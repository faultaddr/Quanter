#!/usr/bin/env python3
"""
å¤šå› å­ç­–ç•¥ä½¿ç”¨æŒ‡å—
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨100+æŠ€æœ¯æŒ‡æ ‡è¿›è¡Œé‡åŒ–åˆ†æ
"""

import pandas as pd
import numpy as np
from quant_trade_a_share.data.data_fetcher import DataFetcher
import matplotlib.pyplot as plt
import seaborn as sns

def get_available_factors():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æŠ€æœ¯æŒ‡æ ‡/å› å­
    """
    factors = [
        # ä»·æ ¼ç›¸å…³å› å­
        'ma_5', 'ma_10', 'ma_20', 'ma_30',  # ç§»åŠ¨å¹³å‡çº¿
        'rsi',  # ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
        'momentum',  # åŠ¨é‡æŒ‡æ ‡
        'log_return',  # å¯¹æ•°æ”¶ç›Šç‡

        # MACDç›¸å…³å› å­
        'macd', 'signal', 'histogram',

        # å¸ƒæ—å¸¦å› å­
        'bb_middle', 'bb_upper', 'bb_lower',

        # æ³¢åŠ¨ç‡å› å­
        'volatility', 'hl_volatility', 'atr',

        # æˆäº¤é‡å› å­
        'volume_sma', 'volume_ratio', 'vpt',

        # ä»·æ ¼ä½ç½®å› å­
        'hl_ratio', 'price_position',

        # éšæœºæŒ‡æ ‡
        'williams_r', 'stoch_k', 'stoch_d',

        # è¶‹åŠ¿å› å­
        'trend', 'roc',

        # åŸºç¡€ä»·æ ¼å› å­
        'open', 'high', 'low', 'close', 'volume'
    ]

    print("ğŸ“Š å¯ç”¨æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨:")
    for i, factor in enumerate(factors, 1):
        print(f"{i:2d}. {factor}")

    print(f"\næ€»è®¡: {len(factors)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
    return factors

def build_multi_factor_strategy(data):
    """
    æ„å»ºå¤šå› å­ç­–ç•¥
    """
    # æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«æŠ€æœ¯æŒ‡æ ‡
    if data.empty:
        print("âŒ æ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ„å»ºç­–ç•¥")
        return None

    print(f"ğŸ“ˆ åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"ğŸ“Š å¯ç”¨åˆ—: {list(data.columns)}")

    # è®¡ç®—é¢å¤–çš„é«˜çº§å› å­
    df = data.copy()

    # æ—¶é—´åºåˆ—å› å­
    df['returns'] = df['close'].pct_change()
    df['volatility_20'] = df['returns'].rolling(20).std()

    # å¤šæ—¶é—´å‘¨æœŸç§»åŠ¨å¹³å‡
    for period in [5, 10, 20, 30, 50, 100]:
        df[f'ma_{period}'] = df['close'].rolling(window=period).mean()
        df[f'price_to_ma_{period}'] = df['close'] / df[f'ma_{period}']

    # å¤šæ—¶é—´å‘¨æœŸRSI
    for period in [7, 14, 21]:
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))

    # æˆäº¤é‡ç›¸å…³å› å­
    for period in [5, 10, 20]:
        df[f'volume_ma_{period}'] = df['volume'].rolling(window=period).mean()
        df[f'volume_ratio_{period}'] = df['volume'] / df[f'volume_ma_{period}']

    # ä»·é‡å…³ç³»å› å­
    df['price_volume_trend'] = (df['volume'] * (df['close'] - df['close'].shift(1)) / df['close'].shift(1)).cumsum()

    # é«˜çº§æ³¢åŠ¨ç‡å› å­
    df['realized_volatility'] = df['log_return'].rolling(10).std() * np.sqrt(252)

    # å½¢æ€è¯†åˆ«å› å­
    df['doji'] = np.where(abs(df['close'] - df['open']) / df['open'] < 0.005, 1, 0)  # åå­—æ˜Ÿ
    df['hammer'] = np.where((df['high'] - df['low']) > 3 * abs(df['close'] - df['open']) &
                           (df['close'] == df['high']) | (df['open'] == df['high']), 1, 0)  # é”¤å¤´çº¿

    print(f"ğŸ“ˆ æ·»åŠ å› å­åæ•°æ®å½¢çŠ¶: {df.shape}")

    # åˆ›å»ºç®€å•çš„å¤šå› å­ä¿¡å·
    df['factor_score'] = 0.0

    # RSIä¿¡å· (åè½¬ä¿¡å·)
    df['rsi_signal'] = np.where(df['rsi'] < 30, 1,  # è¶…å–ä¹°å…¥
                               np.where(df['rsi'] > 70, -1, 0))  # è¶…ä¹°å–å‡º

    # å‡çº¿äº¤å‰ä¿¡å·
    df['ma_signal'] = np.where(df['close'] > df['ma_20'], 1, -1)

    # ä»·æ ¼çªç ´ä¿¡å·
    df['breakout_signal'] = np.where(df['close'] > df['bb_upper'], 1,
                                    np.where(df['close'] < df['bb_lower'], -1, 0))

    # ç»¼åˆä¿¡å·
    df['composite_signal'] = (df['rsi_signal'] * 0.3 +
                             df['ma_signal'] * 0.4 +
                             df['breakout_signal'] * 0.3)

    # æ ¹æ®ä¿¡å·è®¡ç®—æ”¶ç›Šé¢„æµ‹
    df['predicted_returns'] = df['composite_signal'].shift(1) * df['returns']

    return df

def analyze_factor_performance(data, factor_name='composite_signal'):
    """
    åˆ†æå› å­è¡¨ç°
    """
    if data is None or factor_name not in data.columns:
        print(f"âŒ å› å­ {factor_name} ä¸å­˜åœ¨æˆ–æ•°æ®ä¸ºç©º")
        return

    # è¿‡æ»¤æ‰NaNå€¼
    clean_data = data.dropna(subset=[factor_name, 'returns'])

    if clean_data.empty:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç”¨äºåˆ†æ {factor_name}")
        return

    # æŒ‰å› å­å€¼åˆ†ç»„
    clean_data['factor_decile'] = pd.qcut(clean_data[factor_name], 10, labels=False, duplicates='drop')

    # è®¡ç®—å„åˆ†ä½çš„å¹³å‡æ”¶ç›Š
    factor_returns = clean_data.groupby('factor_decile')['returns'].mean()

    print(f"ğŸ“Š {factor_name} å› å­åˆ†ä½åˆ†æ:")
    print(factor_returns)

    # ä¿¡æ¯æ¯”ç‡
    ir = factor_returns.mean() / factor_returns.std() if factor_returns.std() != 0 else 0
    print(f"ğŸ“ˆ ä¿¡æ¯æ¯”ç‡ (IR): {ir:.4f}")

    return factor_returns

def run_multi_factor_analysis():
    """
    è¿è¡Œå®Œæ•´çš„å¤šå› å­åˆ†æ
    """
    print("=" * 80)
    print("ğŸ¯ é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - å¤šå› å­ç­–ç•¥æ¼”ç¤º")
    print("=" * 80)

    # 1. æ˜¾ç¤ºå¯ç”¨å› å­
    available_factors = get_available_factors()

    # 2. è·å–æ•°æ®
    print("\nğŸ”„ è·å–è‚¡ç¥¨æ•°æ®...")
    fetcher = DataFetcher()

    try:
        # è·å–æ ·æœ¬è‚¡ç¥¨æ•°æ®
        data = fetcher.fetch('sh600023', '2025-01-01', '2026-01-01', source='ashare')

        if data is None or data.empty:
            print("âš ï¸  è·å–æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            dates = pd.date_range('2025-01-01', '2026-01-01', freq='D')
            n = len(dates)
            prices = 5 + np.cumsum(np.random.randn(n) * 0.02)  # éšæœºæ¸¸èµ°

            data = pd.DataFrame({
                'open': prices * (1 + np.random.randn(n) * 0.005),
                'high': prices * (1 + abs(np.random.randn(n)) * 0.01),
                'low': prices * (1 - abs(np.random.randn(n)) * 0.01),
                'close': prices,
                'volume': np.random.randint(1000000, 10000000, n)
            }, index=dates)

            # è®¡ç®—åŸºç¡€æŠ€æœ¯æŒ‡æ ‡
            data['ma_5'] = data['close'].rolling(5).mean()
            data['ma_10'] = data['close'].rolling(10).mean()
            data['ma_20'] = data['close'].rolling(20).mean()
            data['rsi'] = 50 + np.random.randn(len(data)) * 10  # æ¨¡æ‹ŸRSI
            data['returns'] = data['close'].pct_change()

        # 3. æ„å»ºå¤šå› å­ç­–ç•¥
        print("\nğŸ—ï¸  æ„å»ºå¤šå› å­ç­–ç•¥...")
        enriched_data = build_multi_factor_strategy(data)

        if enriched_data is not None:
            print(f"âœ… ç­–ç•¥æ„å»ºå®Œæˆï¼Œå½“å‰åŒ…å« {len(enriched_data.columns)} ä¸ªå› å­")

            # 4. åˆ†æå› å­æ€§èƒ½
            print("\nğŸ“Š åˆ†æå› å­è¡¨ç°...")
            analyze_factor_performance(enriched_data, 'composite_signal')

            # 5. è®¡ç®—ç­–ç•¥æ”¶ç›Š
            if 'predicted_returns' in enriched_data.columns:
                cumulative_return = (1 + enriched_data['predicted_returns']).cumprod()
                buy_hold_return = (1 + enriched_data['returns']).cumprod()

                print(f"\nğŸ“ˆ ç­–ç•¥ç´¯è®¡æ”¶ç›Š: {(cumulative_return.iloc[-1] - 1) * 100:.2f}%")
                print(f"ğŸ“ˆ ä¹°å…¥æŒæœ‰æ”¶ç›Š: {(buy_hold_return.iloc[-1] - 1) * 100:.2f}%")

                # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
                excess_returns = enriched_data['predicted_returns'] - enriched_data['returns']
                sharpe_ratio = excess_returns.mean() / (excess_returns.std() + 1e-10) * np.sqrt(252) if excess_returns.std() != 0 else 0
                print(f"ğŸ“Š å¤æ™®æ¯”ç‡: {sharpe_ratio:.4f}")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def create_factor_exposure_matrix():
    """
    åˆ›å»ºå› å­æš´éœ²çŸ©é˜µç¤ºä¾‹
    """
    print("\nğŸ“‹ å› å­æš´éœ²çŸ©é˜µç¤ºä¾‹:")

    # æ¨¡æ‹Ÿå‡ ä¸ªå› å­çš„æš´éœ²åº¦
    factors = ['MA_Ratio', 'RSI_Signal', 'Volume_Momentum', 'Volatility_Regime', 'Momentum_Factor']
    stocks = ['SH600000', 'SH600023', 'SZ000001', 'SH600519', 'SZ300770']

    np.random.seed(42)
    exposure_matrix = pd.DataFrame(
        np.random.randn(len(stocks), len(factors)),
        index=stocks,
        columns=factors
    )

    print(exposure_matrix.round(3))

    # è®¡ç®—å› å­ç›¸å…³æ€§
    print("\nğŸ”— å› å­é—´ç›¸å…³æ€§:")
    factor_corr = exposure_matrix.corr()
    print(factor_corr.round(3))

    return exposure_matrix

if __name__ == "__main__":
    run_multi_factor_analysis()
    create_factor_exposure_matrix()

    print("\n" + "="*80)
    print("ğŸ’¡ å¤šå› å­ç­–ç•¥ä½¿ç”¨æŒ‡å—æ€»ç»“:")
    print("="*80)
    print("1. æ•°æ®è·å–: ä½¿ç”¨ DataFetcher è·å–å†å²æ•°æ®")
    print("2. å› å­å·¥ç¨‹: åˆ©ç”¨å†…ç½®æŠ€æœ¯æŒ‡æ ‡å’Œè‡ªå®šä¹‰å› å­")
    print("3. ç­–ç•¥æ„å»º: ç»“åˆå¤šä¸ªå› å­ç”Ÿæˆç»¼åˆä¿¡å·")
    print("4. é£é™©æ§åˆ¶: ç›‘æ§å› å­æš´éœ²å’Œç›¸å…³æ€§")
    print("5. ç»©æ•ˆè¯„ä¼°: è®¡ç®—æ”¶ç›Šã€é£é™©è°ƒæ•´æ”¶ç›Šç­‰æŒ‡æ ‡")
    print("="*80)