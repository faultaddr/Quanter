"""
é£é™©ç®¡ç†æ¨¡å—
åˆ©ç”¨Qlibçš„é£é™©æ¨¡å‹åŠ å¼ºæŠ•èµ„ç»„åˆç®¡ç†
"""
import sys
import os
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

try:
    import qlib
    from qlib.config import REG_CN as REGION_CN
    from qlib.data import D
    from qlib.riskmodel import RiskModel
    from qlib.portfolio import Portfolio
    from qlib.contrib.riskmodel import StructuredRM
    QLIB_AVAILABLE = True
except ImportError:
    QLIB_AVAILABLE = False
    print("âš ï¸ Qlib æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€é£é™©ç®¡ç†åŠŸèƒ½")

from quant_trade_a_share.models.model_fusion import ModelFusion
from quant_trade_a_share.factors.factor_library_expansion import FactorLibraryExpansion

class PortfolioRiskManagement:
    """
    æŠ•èµ„ç»„åˆé£é™©ç®¡ç†ç±»
    åˆ©ç”¨ Qlib é£é™©æ¨¡å‹åŠ å¼ºæŠ•èµ„ç»„åˆç®¡ç†
    """

    def __init__(self, provider_uri="~/.qlib/qlib_data/cn_data"):
        """åˆå§‹åŒ–é£é™©ç®¡ç†å™¨"""
        self.provider_uri = provider_uri
        self.risk_model = None
        self.initialized = False

        # å­æ¨¡å—
        self.model_fusion = ModelFusion()
        self.factor_library = FactorLibraryExpansion()

        if QLIB_AVAILABLE:
            try:
                qlib.init(provider_uri=self.provider_uri, region=REGION_CN)
                self.initialized = True
                print("âœ… é£é™©ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ Qlib åˆå§‹åŒ–å¤±è´¥: {e}")
                print("ğŸ’¡ æç¤º: å®‰è£… Qlib å¹¶ä¸‹è½½æ•°æ®ä»¥å¯ç”¨å®Œæ•´é£é™©åŠŸèƒ½")
        else:
            print("âš ï¸ Qlib ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€é£é™©åŠŸèƒ½")

        # é£é™©å‚æ•°è®¾ç½®
        self.risk_limits = {
            'max_position_size': 0.1,      # æœ€å¤§å•è‚¡å æ¯” 10%
            'max_sector_exposure': 0.3,    # æœ€å¤§è¡Œä¸šæš´éœ² 30%
            'max_beta': 1.2,              # æœ€å¤§è´å¡”å€¼
            'max_drawdown': 0.15,         # æœ€å¤§å›æ’¤ 15%
            'volatility_target': 0.2      # æ³¢åŠ¨ç‡ç›®æ ‡ 20%
        }

        # é£é™©æŒ‡æ ‡å­˜å‚¨
        self.risk_metrics = {}
        self.portfolio_history = []

    def calculate_basic_risk_metrics(self, returns: pd.Series, benchmark_returns: pd.Series = None) -> Dict[str, float]:
        """
        è®¡ç®—åŸºç¡€é£é™©æŒ‡æ ‡

        Args:
            returns: æŠ•èµ„ç»„åˆæ”¶ç›Šç‡åºåˆ—
            benchmark_returns: åŸºå‡†æ”¶ç›Šç‡åºåˆ—
        """
        if returns.empty:
            return {}

        metrics = {}

        # æ”¶ç›Šç‡ç»Ÿè®¡
        metrics['total_return'] = (1 + returns).prod() - 1
        metrics['annual_return'] = (1 + returns.mean()) ** 252 - 1
        metrics['volatility'] = returns.std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡

        # å¤æ™®æ¯”ç‡
        risk_free_rate = 0.03  # å‡è®¾æ— é£é™©åˆ©ç‡ä¸º 3%
        excess_return = metrics['annual_return'] - risk_free_rate
        metrics['sharpe_ratio'] = excess_return / metrics['volatility'] if metrics['volatility'] != 0 else 0

        # æœ€å¤§å›æ’¤
        metrics['max_drawdown'] = self._calculate_max_drawdown(returns)

        # èƒœç‡
        metrics['win_rate'] = (returns > 0).sum() / len(returns) if len(returns) > 0 else 0

        # æ³¢åŠ¨ç‡ä¸‹è¡Œæ¯”ç‡
        negative_returns = returns[returns < 0]
        if len(negative_returns) > 0:
            downside_dev = np.sqrt((negative_returns ** 2).mean())
            metrics['sortino_ratio'] = excess_return / (downside_dev * np.sqrt(252)) if downside_dev != 0 else 0
        else:
            metrics['sortino_ratio'] = float('inf')

        # Calmaræ¯”ç‡ï¼ˆå›æ’¤æ¯”ç‡ï¼‰
        metrics['calmar_ratio'] = excess_return / abs(metrics['max_drawdown']) if metrics['max_drawdown'] != 0 else 0

        # Alpha å’Œ Beta (å¦‚æœæœ‰åŸºå‡†)
        if benchmark_returns is not None and not benchmark_returns.empty:
            # å¯¹é½ç´¢å¼•
            aligned_returns, aligned_benchmark = returns.align(benchmark_returns, join='inner')

            # Beta
            if aligned_benchmark.var() != 0:
                metrics['beta'] = aligned_returns.cov(aligned_benchmark) / aligned_benchmark.var()
            else:
                metrics['beta'] = 0

            # Alpha
            expected_return = risk_free_rate + metrics['beta'] * (aligned_benchmark.mean() * 252 - risk_free_rate)
            metrics['alpha'] = metrics['annual_return'] - expected_return
        else:
            metrics['beta'] = 1.0  # é»˜è®¤Betaä¸º1.0
            metrics['alpha'] = 0.0

        return metrics

    def _calculate_max_drawdown(self, returns: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        try:
            cumulative = (1 + returns).cumprod()
            rolling_max = cumulative.expanding().max()
            drawdowns = (cumulative - rolling_max) / rolling_max
            return drawdowns.min()
        except:
            return 0.0

    def estimate_covariance_matrix(self, returns: pd.DataFrame, method: str = 'ledoit_wolf') -> pd.DataFrame:
        """
        ä¼°è®¡åæ–¹å·®çŸ©é˜µ

        Args:
            returns: èµ„äº§æ”¶ç›Šç‡çŸ©é˜µ
            method: ä¼°è®¡æ–¹æ³• ('sample', 'ledoit_wolf', 'constant_correlation')
        """
        if returns.empty or returns.isna().all().all():
            return pd.DataFrame()

        try:
            if method == 'ledoit_wolf':
                # Ledoit-Wolf shrinkage estimator
                from sklearn.covariance import LedoitWolf
                lw = LedoitWolf()
                cov_matrix = lw.fit(returns.dropna()).covariance_
                return pd.DataFrame(cov_matrix,
                                  index=returns.columns,
                                  columns=returns.columns)

            elif method == 'constant_correlation':
                # Constant correlation model
                corrmatrix = returns.corr()
                stds = returns.std()
                cov_matrix = pd.DataFrame(index=returns.columns, columns=returns.columns)

                for i in returns.columns:
                    for j in returns.columns:
                        if i == j:
                            cov_matrix.loc[i, j] = stds[i]**2
                        else:
                            avg_corr = corrmatrix.values[corrmatrix.columns != i, corrmatrix.columns != j].mean()
                            cov_matrix.loc[i, j] = avg_corr * stds[i] * stds[j]

                return cov_matrix

            else:  # Sample covariance
                return returns.cov().fillna(0)

        except Exception as e:
            print(f"âš ï¸ åæ–¹å·®çŸ©é˜µä¼°è®¡å¤±è´¥: {e}")
            # è¿”å›å•ä½çŸ©é˜µä½œä¸ºå¤‡é€‰
            identity = np.eye(len(returns.columns))
            return pd.DataFrame(identity,
                              index=returns.columns,
                              columns=returns.columns)

    def calculate_portfolio_risk_contributions(self, weights: pd.Series, returns: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—æŠ•èµ„ç»„åˆä¸­å„èµ„äº§çš„é£é™©è´¡çŒ®

        Args:
            weights: èµ„äº§æƒé‡
            returns: èµ„äº§æ”¶ç›Šç‡çŸ©é˜µ
        """
        if weights.empty or returns.empty:
            return pd.Series()

        try:
            # è®¡ç®—åæ–¹å·®çŸ©é˜µ
            cov_matrix = self.estimate_covariance_matrix(returns)

            # æŠ•èµ„ç»„åˆæ€»ä½“é£é™©
            portfolio_variance = weights.dot(cov_matrix).dot(weights)
            portfolio_vol = np.sqrt(portfolio_variance)

            # è¾¹é™…é£é™©è´¡çŒ®
            marginal_contrib = (2 * cov_matrix.dot(weights)) / (2 * portfolio_vol)

            # ä¸ªä½“é£é™©è´¡çŒ®
            risk_contributions = weights * marginal_contrib

            return risk_contributions

        except Exception as e:
            print(f"âš ï¸ é£é™©è´¡çŒ®è®¡ç®—å¤±è´¥: {e}")
            return pd.Series()

    def optimize_portfolio(self, returns: pd.DataFrame,
                         risk_model: str = 'min_variance',
                         constraints: Dict = None) -> pd.Series:
        """
        æŠ•èµ„ç»„åˆä¼˜åŒ–

        Args:
            returns: èµ„äº§æ”¶ç›Šç‡çŸ©é˜µ
            risk_model: é£é™©æ¨¡å‹ç±»å‹ ('min_variance', 'risk_parity', 'max_diversification')
            constraints: çº¦æŸæ¡ä»¶
        """
        if returns.empty:
            return pd.Series()

        try:
            n_assets = len(returns.columns)

            # è®¾ç½®é»˜è®¤çº¦æŸ
            if constraints is None:
                constraints = {
                    'min_weight': 0.0,      # æœ€å°æƒé‡
                    'max_weight': 0.3,      # æœ€å¤§æƒé‡
                    'long_only': True       # åªåšå¤š
                }

            # è®¡ç®—æœŸæœ›æ”¶ç›Šç‡ï¼ˆä½¿ç”¨å†å²å¹³å‡ï¼‰
            expected_returns = returns.mean() * 252

            # è®¡ç®—åæ–¹å·®çŸ©é˜µ
            cov_matrix = self.estimate_covariance_matrix(returns)

            # æ ¹æ®ä¸åŒæ¨¡å‹è®¡ç®—æœ€ä¼˜æƒé‡
            if risk_model == 'min_variance':
                weights = self._min_variance_optimization(cov_matrix, constraints)
            elif risk_model == 'risk_parity':
                weights = self._risk_parity_optimization(cov_matrix, constraints)
            elif risk_model == 'max_diversification':
                weights = self._max_diversification_optimization(cov_matrix, expected_returns, constraints)
            else:  # mean_variance
                weights = self._mean_variance_optimization(expected_returns, cov_matrix, constraints)

            # æ ‡å‡†åŒ–æƒé‡ä½¿æ€»å’Œä¸º1
            if weights.sum() != 0:
                weights = weights / weights.sum()

            return weights

        except Exception as e:
            print(f"âš ï¸ æŠ•èµ„ç»„åˆä¼˜åŒ–å¤±è´¥: {e}")
            # è¿”å›ç­‰æƒé‡ä½œä¸ºå¤‡é€‰
            equal_weights = pd.Series(1.0/n_assets, index=returns.columns)
            return equal_weights

    def _min_variance_optimization(self, cov_matrix: pd.DataFrame, constraints: Dict) -> pd.Series:
        """æœ€å°æ–¹å·®ä¼˜åŒ–"""
        try:
            from scipy.optimize import minimize

            n = len(cov_matrix)
            def objective(w):
                return w.T @ cov_matrix @ w

            constraints_list = [
                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}  # æƒé‡å’Œä¸º1
            ]

            bounds = [(constraints.get('min_weight', 0), constraints.get('max_weight', 1)) for _ in range(n)]

            if constraints.get('long_only', True):
                bounds = [(max(0, b[0]), min(1, b[1])) for b in bounds]

            # åˆå§‹æƒé‡ï¼ˆç­‰æƒï¼‰
            x0 = np.array([1/n] * n)

            result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints_list)

            if result.success:
                return pd.Series(result.x, index=cov_matrix.columns)
            else:
                print("âš ï¸ ä¼˜åŒ–æœªæˆåŠŸï¼Œä½¿ç”¨ç­‰æƒé‡")
                return pd.Series([1/n] * n, index=cov_matrix.columns)

        except:
            # å¦‚æœscipyä¸å¯ç”¨ï¼Œè¿”å›ç­‰æƒé‡
            n = len(cov_matrix)
            return pd.Series([1/n] * n, index=cov_matrix.columns)

    def _risk_parity_optimization(self, cov_matrix: pd.DataFrame, constraints: Dict) -> pd.Series:
        """é£é™©å¹³ä»·ä¼˜åŒ–"""
        try:
            # ç®€åŒ–çš„é£é™©å¹³ä»·ç®—æ³•
            # è®¡ç®—æ¯ä¸ªèµ„äº§çš„æ³¢åŠ¨ç‡ä½œä¸ºåˆå§‹ä¼°è®¡
            volatilities = np.sqrt(np.diag(cov_matrix))

            # ä½¿ç”¨é€†æ³¢åŠ¨ç‡åŠ æƒï¼ˆç®€åŒ–ç‰ˆé£é™©å¹³ä»·ï¼‰
            weights = 1 / volatilities
            weights = weights / weights.sum()

            # åº”ç”¨çº¦æŸ
            weights = np.clip(weights, constraints.get('min_weight', 0), constraints.get('max_weight', 1))
            weights = weights / weights.sum()  # é‡æ–°æ ‡å‡†åŒ–

            return pd.Series(weights, index=cov_matrix.columns)

        except:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›ç­‰æƒé‡
            n = len(cov_matrix)
            return pd.Series([1/n] * n, index=cov_matrix.columns)

    def _max_diversification_optimization(self, cov_matrix: pd.DataFrame, expected_returns: pd.Series, constraints: Dict) -> pd.Series:
        """æœ€å¤§åˆ†æ•£åŒ–ä¼˜åŒ–"""
        try:
            # æœ€å¤§åˆ†æ•£åŒ–æ¯”ç‡ = æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡ / å„èµ„äº§æƒé‡*æ³¢åŠ¨ç‡ä¹‹å’Œ
            volatilities = np.sqrt(np.diag(cov_matrix))

            # åˆå§‹æƒé‡ä¼°è®¡ï¼ˆç­‰æƒï¼‰
            n = len(cov_matrix)
            weights = np.array([1/n] * n)

            # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
            correlation = cov_matrix / np.outer(volatilities, volatilities)

            # ä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼šæœ€å¤§åŒ–åˆ†æ•£åŒ–æ¯”ç‡
            for _ in range(100):  # è¿­ä»£ä¼˜åŒ–
                # å½“å‰æƒé‡ä¸‹çš„åˆ†æ•£åŒ–æ¯”ç‡
                portfolio_vol = np.sqrt(weights @ cov_matrix @ weights)
                weighted_vols = np.sum(weights * volatilities)
                diversification_ratio = portfolio_vol / weighted_vols if weighted_vols != 0 else 0

                # æ¢¯åº¦ä¸Šå‡æ›´æ–°ï¼ˆç®€åŒ–ç‰ˆï¼‰
                grad = (weights * volatilities) / weighted_vols - (cov_matrix @ weights) / portfolio_vol
                weights = weights + 0.01 * grad  # å­¦ä¹ ç‡0.01

                # åº”ç”¨çº¦æŸå¹¶é‡æ–°æ ‡å‡†åŒ–
                weights = np.clip(weights, constraints.get('min_weight', 0), constraints.get('max_weight', 1))
                weights = np.maximum(weights, 0)  # ç¡®ä¿éè´Ÿ
                weights = weights / weights.sum() if weights.sum() != 0 else np.array([1/n] * n)

            return pd.Series(weights, index=cov_matrix.columns)

        except:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›ç­‰æƒé‡
            n = len(cov_matrix)
            return pd.Series([1/n] * n, index=cov_matrix.columns)

    def _mean_variance_optimization(self, expected_returns: pd.Series, cov_matrix: pd.DataFrame, constraints: Dict) -> pd.Series:
        """å‡å€¼-æ–¹å·®ä¼˜åŒ–"""
        try:
            from scipy.optimize import minimize

            n = len(expected_returns)
            target_return = expected_returns.mean()  # ç›®æ ‡æ”¶ç›Šç‡è®¾ä¸ºå¹³å‡å€¼

            def objective(w):
                return w.T @ cov_matrix @ w  # æœ€å°åŒ–é£é™©ï¼ˆæ–¹å·®ï¼‰

            constraints_list = [
                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},  # æƒé‡å’Œä¸º1
                {'type': 'eq', 'fun': lambda w: w.T @ expected_returns - target_return}  # ç›®æ ‡æ”¶ç›Šç‡
            ]

            bounds = [(constraints.get('min_weight', 0), constraints.get('max_weight', 1)) for _ in range(n)]

            if constraints.get('long_only', True):
                bounds = [(max(0, b[0]), min(1, b[1])) for b in bounds]

            # åˆå§‹æƒé‡ï¼ˆç­‰æƒï¼‰
            x0 = np.array([1/n] * n)

            result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints_list)

            if result.success:
                return pd.Series(result.x, index=expected_returns.index)
            else:
                print("âš ï¸ ä¼˜åŒ–æœªæˆåŠŸï¼Œä½¿ç”¨ç­‰æƒé‡")
                return pd.Series([1/n] * n, index=expected_returns.index)

        except:
            # å¦‚æœscipyä¸å¯ç”¨ï¼Œè¿”å›ç­‰æƒé‡
            n = len(expected_returns)
            return pd.Series([1/n] * n, index=expected_returns.index)

    def monitor_position_risk(self, positions: Dict[str, float], current_prices: Dict[str, float],
                            threshold_alerts: bool = True) -> Dict[str, Any]:
        """
        ç›‘æ§å¤´å¯¸é£é™©

        Args:
            positions: æŒä»“å­—å…¸ {symbol: quantity}
            current_prices: å½“å‰ä»·æ ¼å­—å…¸ {symbol: price}
            threshold_alerts: æ˜¯å¦å¯ç”¨é˜ˆå€¼è­¦æŠ¥
        """
        if not positions or not current_prices:
            return {}

        risk_report = {}

        # è®¡ç®—å¸‚å€¼
        market_values = {}
        total_value = 0
        for symbol, qty in positions.items():
            if symbol in current_prices:
                value = qty * current_prices[symbol]
                market_values[symbol] = value
                total_value += value

        risk_report['total_portfolio_value'] = total_value
        risk_report['position_sizes'] = {}
        risk_report['alerts'] = []

        if total_value > 0:
            # è®¡ç®—å„å¤´å¯¸å æ¯”å’Œé£é™©
            for symbol, mv in market_values.items():
                pct_of_portfolio = mv / total_value
                risk_report['position_sizes'][symbol] = {
                    'market_value': mv,
                    'percentage_of_portfolio': pct_of_portfolio
                }

                # æ£€æŸ¥é˜ˆå€¼è­¦æŠ¥
                if threshold_alerts:
                    if pct_of_portfolio > self.risk_limits['max_position_size']:
                        risk_report['alerts'].append({
                            'type': 'POSITION_SIZE_EXCEEDED',
                            'symbol': symbol,
                            'current': f"{pct_of_portfolio:.2%}",
                            'limit': f"{self.risk_limits['max_position_size']:.2%}",
                            'severity': 'HIGH'
                        })

        return risk_report

    def simulate_portfolio_scenario(self, returns: pd.DataFrame, scenario: str = 'stress',
                                  severity: float = 1.0) -> Dict[str, Any]:
        """
        æƒ…æ™¯åˆ†æ

        Args:
            returns: å†å²æ”¶ç›Šç‡æ•°æ®
            scenario: æƒ…æ™¯ç±»å‹ ('stress', 'normal', 'bull', 'bear')
            severity: ä¸¥é‡ç¨‹åº¦ (0-1)
        """
        if returns.empty:
            return {}

        scenarios = {
            'stress': {
                'return_multiplier': -1.5,
                'volatility_multiplier': 2.0,
                'correlation_shift': 0.3
            },
            'normal': {
                'return_multiplier': 1.0,
                'volatility_multiplier': 1.0,
                'correlation_shift': 0.0
            },
            'bull': {
                'return_multiplier': 1.5,
                'volatility_multiplier': 0.8,
                'correlation_shift': -0.1
            },
            'bear': {
                'return_multiplier': -1.0,
                'volatility_multiplier': 1.5,
                'correlation_shift': 0.2
            }
        }

        if scenario not in scenarios:
            scenario = 'normal'

        scenario_params = scenarios[scenario]

        # è°ƒæ•´æ”¶ç›Šç‡
        adj_returns = returns * scenario_params['return_multiplier'] * severity
        adj_returns = adj_returns * scenario_params['volatility_multiplier'] * severity

        # è°ƒæ•´ç›¸å…³æ€§
        # (ç®€åŒ–å¤„ç†ï¼Œå®é™…æƒ…å†µéœ€è¦æ›´å¤æ‚çš„åæ–¹å·®çŸ©é˜µè°ƒæ•´)

        # è®¡ç®—è°ƒæ•´åçš„é£é™©æŒ‡æ ‡
        scenario_metrics = self.calculate_basic_risk_metrics(adj_returns.mean(axis=1))  # ç®€åŒ–ä¸ºç­‰æƒæŠ•èµ„ç»„åˆ

        return {
            'scenario': scenario,
            'severity': severity,
            'adjusted_returns': adj_returns,
            'risk_metrics': scenario_metrics,
            'params_used': scenario_params
        }

    def apply_risk_adjustment(self, signals: pd.Series, risk_metrics: Dict[str, float],
                            adjustment_method: str = 'volatility_scaling') -> pd.Series:
        """
        åº”ç”¨é£é™©è°ƒæ•´

        Args:
            signals: åŸå§‹ä¿¡å·
            risk_metrics: é£é™©æŒ‡æ ‡
            adjustment_method: è°ƒæ•´æ–¹æ³•
        """
        if signals.empty or not risk_metrics:
            return signals

        adjusted_signals = signals.copy()

        if adjustment_method == 'volatility_scaling':
            # æ³¢åŠ¨ç‡ç¼©æ”¾
            current_vol = risk_metrics.get('volatility', 0.2)  # é»˜è®¤20%å¹´åŒ–æ³¢åŠ¨ç‡
            target_vol = self.risk_limits['volatility_target']

            if current_vol > 0:
                scaling_factor = target_vol / current_vol
                # ç¼©æ”¾ä¿¡å·å¼ºåº¦
                adjusted_signals = adjusted_signals * min(scaling_factor, 1.0)  # ä¸å¢åŠ é£é™©ï¼Œåªå‡å°‘

        elif adjustment_method == 'drawdown_control':
            # å›æ’¤æ§åˆ¶
            current_drawdown = risk_metrics.get('max_drawdown', 0)
            max_allowed_drawdown = self.risk_limits['max_drawdown']

            if abs(current_drawdown) > max_allowed_drawdown:
                # å¦‚æœè¶…è¿‡æœ€å¤§å›æ’¤é™åˆ¶ï¼Œé™ä½ä¿¡å·å¼ºåº¦
                reduction_factor = max(0, 1 - (abs(current_drawdown) - max_allowed_drawdown) / max_allowed_drawdown)
                adjusted_signals = adjusted_signals * reduction_factor

        elif adjustment_method == 'beta_adjustment':
            # Betaè°ƒæ•´
            current_beta = risk_metrics.get('beta', 1.0)
            max_beta = self.risk_limits['max_beta']

            if current_beta > max_beta:
                # å¦‚æœBetaè¿‡é«˜ï¼Œé™ä½ä¿¡å·å¼ºåº¦
                reduction_factor = max(0, max_beta / current_beta)
                adjusted_signals = adjusted_signals * reduction_factor

        return adjusted_signals

    def generate_risk_report(self, portfolio_data: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆé£é™©æŠ¥å‘Š

        Args:
            portfolio_data: æŠ•èµ„ç»„åˆæ•°æ®
        """
        report = []
        report.append("="*60)
        report.append("æŠ•èµ„ç»„åˆé£é™©ç®¡ç†æŠ¥å‘Š")
        report.append("="*60)

        if 'risk_metrics' in portfolio_data:
            metrics = portfolio_data['risk_metrics']
            report.append(f"æ€»æ”¶ç›Š: {metrics.get('total_return', 0):.2%}")
            report.append(f"å¹´åŒ–æ”¶ç›Š: {metrics.get('annual_return', 0):.2%}")
            report.append(f"æ³¢åŠ¨ç‡: {metrics.get('volatility', 0):.2%}")
            report.append(f"å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 0):.3f}")
            report.append(f"æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 0):.2%}")
            report.append(f"Beta: {metrics.get('beta', 0):.3f}")
            report.append(f"Alpha: {metrics.get('alpha', 0):.3f}")
            report.append(f"èƒœç‡: {metrics.get('win_rate', 0):.2%}")
            report.append(f"Sortinoæ¯”ç‡: {metrics.get('sortino_ratio', 0):.3f}")
            report.append(f"Calmaræ¯”ç‡: {metrics.get('calmar_ratio', 0):.3f}")

        if 'position_sizes' in portfolio_data:
            report.append("\nå¤´å¯¸è§„æ¨¡:")
            for symbol, pos_info in portfolio_data['position_sizes'].items():
                report.append(f"  {symbol}: {pos_info['percentage_of_portfolio']:.2%} ({pos_info['market_value']:.2f}å…ƒ)")

        if 'alerts' in portfolio_data and portfolio_data['alerts']:
            report.append("\né£é™©è­¦æŠ¥:")
            for alert in portfolio_data['alerts']:
                report.append(f"  [{alert['severity']}] {alert['type']}: {alert['symbol']} - {alert['current']} (é™åˆ¶: {alert['limit']})")

        report.append("="*60)
        return "\n".join(report)


if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•é£é™©ç®¡ç†æ¨¡å—...")

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    dates = pd.date_range(start='2024-01-01', periods=100, freq='D')
    np.random.seed(42)

    # åˆ›å»ºå¤šèµ„äº§æ”¶ç›Šç‡æ•°æ®
    n_assets = 5
    asset_names = [f'STOCK_{i}' for i in range(n_assets)]

    returns_data = pd.DataFrame(
        np.random.randn(100, n_assets) * 0.02,  # 2%æ—¥æ³¢åŠ¨ç‡
        index=dates,
        columns=asset_names
    )

    # æµ‹è¯•é£é™©ç®¡ç†
    risk_manager = PortfolioRiskManagement()

    print(f"\nğŸ“‹ é£é™©ç®¡ç†ç³»ç»ŸçŠ¶æ€: {'å¯ç”¨' if risk_manager.initialized else 'ä¸å¯ç”¨'}")

    print("\nğŸ¯ ä¸»è¦åŠŸèƒ½:")
    print("â€¢ åŸºç¡€é£é™©æŒ‡æ ‡è®¡ç®—")
    print("â€¢ åæ–¹å·®çŸ©é˜µä¼°è®¡")
    print("â€¢ æŠ•èµ„ç»„åˆä¼˜åŒ–")
    print("â€¢ é£é™©è´¡çŒ®åˆ†æ")
    print("â€¢ å¤´å¯¸ç›‘æ§")
    print("â€¢ æƒ…æ™¯åˆ†æ")
    print("â€¢ é£é™©è°ƒæ•´")
    print("â€¢ é£é™©æŠ¥å‘Šç”Ÿæˆ")

    print("\nğŸ’¡ åº”ç”¨åœºæ™¯:")
    print("1. æŠ•èµ„ç»„åˆæ„å»º")
    print("2. é£é™©æ§åˆ¶")
    print("3. ç»©æ•ˆå½’å› ")
    print("4. ç›‘ç®¡åˆè§„")