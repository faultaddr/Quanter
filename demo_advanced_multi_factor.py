#!/usr/bin/env python3
"""
å¤šå› å­ç­–ç•¥ä½¿ç”¨æŒ‡å—
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨100+æŠ€æœ¯æŒ‡æ ‡è¿›è¡Œé‡åŒ–åˆ†æ
"""

import pandas as pd
import numpy as np
from quant_trade_a_share.data.data_fetcher import DataFetcher
from quant_trade_a_share.utils.eastmoney_data_fetcher import EastMoneyDataFetcher
import matplotlib.pyplot as plt
import seaborn as sns

def get_available_factors():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æŠ€æœ¯æŒ‡æ ‡/å› å­
    """
    factors = [
        # ä»·æ ¼ç›¸å…³å› å­
        'ma_5', 'ma_10', 'ma_20', 'ma_30',  # ç§»åŠ¨å¹³å‡çº¿
        'rsi',  # ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
        'momentum',  # åŠ¨é‡æŒ‡æ ‡
        'log_return',  # å¯¹æ•°æ”¶ç›Šç‡

        # MACDç›¸å…³å› å­
        'macd', 'signal', 'histogram',

        # å¸ƒæ—å¸¦å› å­
        'bb_middle', 'bb_upper', 'bb_lower',

        # æ³¢åŠ¨ç‡å› å­
        'volatility', 'hl_volatility', 'atr',

        # æˆäº¤é‡å› å­
        'volume_sma', 'volume_ratio', 'vpt',

        # ä»·æ ¼ä½ç½®å› å­
        'hl_ratio', 'price_position',

        # éšæœºæŒ‡æ ‡
        'williams_r', 'stoch_k', 'stoch_d',

        # è¶‹åŠ¿å› å­
        'trend', 'roc',

        # åŸºç¡€ä»·æ ¼å› å­
        'open', 'high', 'low', 'close', 'volume'
    ]

    print("ğŸ“Š å¯ç”¨æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨:")
    for i, factor in enumerate(factors, 1):
        print(f"{i:2d}. {factor}")

    print(f"\næ€»è®¡: {len(factors)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
    return factors

def calculate_technical_factors(df):
    """
    ä¸ºDataFrameè®¡ç®—æ‰€æœ‰æŠ€æœ¯å› å­
    """
    if df is None or df.empty:
        return df

    # å¤åˆ¶æ•°æ®æ¡†
    data = df.copy()

    # åŸºç¡€æŒ‡æ ‡
    data['returns'] = data['close'].pct_change()
    data['log_return'] = np.log(data['close'] / data['close'].shift(1))

    # 1. ç§»åŠ¨å¹³å‡çº¿ç³»åˆ—
    for period in [5, 10, 20, 30, 50, 100]:
        data[f'ma_{period}'] = data['close'].rolling(window=period).mean()
        data[f'ema_{period}'] = data['close'].ewm(span=period).mean()
        data[f'price_to_ma_{period}'] = (data['close'] - data[f'ma_{period}']) / data[f'ma_{period}']

    # 2. RSIç³»åˆ—
    for period in [7, 14, 21, 30]:
        delta = data['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        data[f'rsi_{period}'] = 100 - (100 / (1 + rs))

    # 3. MACDç³»åˆ—
    for fast, slow, signal_period in [(12, 26, 9), (10, 20, 5), (5, 15, 3)]:
        exp1_fast = data['close'].ewm(span=fast).mean()
        exp1_slow = data['close'].ewm(span=slow).mean()
        data[f'macd_line_{fast}_{slow}'] = exp1_fast - exp1_slow
        data[f'macd_signal_{fast}_{slow}_{signal_period}'] = data[f'macd_line_{fast}_{slow}'].ewm(span=signal_period).mean()
        data[f'macd_histogram_{fast}_{slow}_{signal_period}'] = data[f'macd_line_{fast}_{slow}'] - data[f'macd_signal_{fast}_{slow}_{signal_period}']

    # 4. å¸ƒæ—å¸¦ç³»åˆ—
    for period in [10, 20, 50]:
        for std_dev in [1, 2, 2.5]:
            bb_middle = data['close'].rolling(window=period).mean()
            bb_std = data['close'].rolling(window=period).std()
            data[f'bb_upper_{period}_{std_dev}'] = bb_middle + (bb_std * std_dev)
            data[f'bb_lower_{period}_{std_dev}'] = bb_middle - (bb_std * std_dev)
            data[f'bb_bandwidth_{period}_{std_dev}'] = (data[f'bb_upper_{period}_{std_dev}'] - data[f'bb_lower_{period}_{std_dev}']) / bb_middle

    # 5. æ³¢åŠ¨ç‡æŒ‡æ ‡
    for period in [10, 20, 30]:
        data[f'volatility_{period}'] = data['returns'].rolling(window=period).std()
        data[f'high_low_range_{period}'] = (data['high'] - data['low']).rolling(window=period).mean()
        data[f'realized_vol_{period}'] = data['log_return'].rolling(window=period).std() * np.sqrt(252)

    # 6. æˆäº¤é‡æŒ‡æ ‡
    for period in [5, 10, 20, 30]:
        data[f'volume_ma_{period}'] = data['volume'].rolling(window=period).mean()
        data[f'volume_ratio_{period}'] = data['volume'] / data[f'volume_ma_{period}']
        data[f'volume_std_{period}'] = data['volume'].rolling(window=period).std()

    # 7. ä»·æ ¼å½¢æ€æŒ‡æ ‡
    data['upper_shadow'] = data['high'] - np.maximum(data['open'], data['close'])
    data['lower_shadow'] = np.minimum(data['open'], data['close']) - data['low']
    data['body_size'] = abs(data['close'] - data['open'])
    data['candle_range'] = data['high'] - data['low']
    data['body_to_range'] = data['body_size'] / data['candle_range']
    data['upper_shadow_to_range'] = data['upper_shadow'] / data['candle_range']
    data['lower_shadow_to_range'] = data['lower_shadow'] / data['candle_range']

    # 8. è¶‹åŠ¿æŒ‡æ ‡
    data['sma_trend_20'] = np.where(data['close'] > data['ma_20'], 1, -1)
    data['sma_trend_50'] = np.where(data['close'] > data['ma_50'], 1, -1)
    data['long_term_trend'] = np.where(data['ma_20'] > data['ma_50'], 1, -1)

    # 9. åŠ¨é‡æŒ‡æ ‡
    for period in [5, 10, 20, 30]:
        data[f'momentum_{period}'] = data['close'] / data['close'].shift(period) - 1
        data[f'roc_{period}'] = ((data['close'] - data['close'].shift(period)) / data['close'].shift(period)) * 100

    # 10. æˆäº¤é‡ä»·æ ¼è¶‹åŠ¿
    for period in [10, 20, 30]:
        data[f'vpt_{period}'] = (data['volume'] * (data['close'] - data['close'].shift(1)) / data['close'].shift(1)).cumsum().rolling(window=period).mean()

    # 11. å¨å»‰æŒ‡æ ‡
    for period in [14, 20, 25]:
        highest_high = data['high'].rolling(window=period).max()
        lowest_low = data['low'].rolling(window=period).min()
        data[f'williams_r_{period}'] = (highest_high - data['close']) / (highest_high - lowest_low) * -100

    # 12. éšæœºæŒ‡æ ‡
    for period in [14, 20, 25]:
        lowest_low = data['low'].rolling(window=period).min()
        highest_high = data['high'].rolling(window=period).max()
        data[f'stoch_k_{period}'] = (data['close'] - lowest_low) / (highest_high - lowest_low) * 100
        data[f'stoch_d_{period}'] = data[f'stoch_k_{period}'].rolling(window=3).mean()

    # 13. å¹³å‡çœŸå®æ³¢å¹…
    data['tr1'] = abs(data['high'] - data['low'])
    data['tr2'] = abs(data['high'] - data['close'].shift(1))
    data['tr3'] = abs(data['low'] - data['close'].shift(1))
    data['true_range'] = pd.concat([data['tr1'], data['tr2'], data['tr3']], axis=1).max(axis=1)
    for period in [14, 20, 25]:
        data[f'atr_{period}'] = data['true_range'].rolling(window=period).mean()

    print(f"ğŸ“ˆ å·²è®¡ç®— {len(data.columns)} ä¸ªæŠ€æœ¯å› å­")
    return data

def build_multi_factor_strategy(data):
    """
    æ„å»ºå¤šå› å­ç­–ç•¥
    """
    if data.empty:
        print("âŒ æ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ„å»ºç­–ç•¥")
        return None

    print(f"ğŸ“ˆ åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"ğŸ“Š å¯ç”¨åˆ—: {list(data.columns)}")

    # è®¡ç®—æŠ€æœ¯å› å­
    df_with_factors = calculate_technical_factors(data)

    if df_with_factors is not None:
        # åˆ›å»ºç®€å•çš„å¤šå› å­ä¿¡å·
        df = df_with_factors.copy()

        # RSIä¿¡å· (åè½¬ä¿¡å·)
        df['rsi_signal'] = np.where(df['rsi_14'] < 30, 1,  # è¶…å–ä¹°å…¥
                                   np.where(df['rsi_14'] > 70, -1, 0))  # è¶…ä¹°å–å‡º

        # å‡çº¿ä¿¡å·
        df['ma_signal'] = np.where(df['close'] > df['ma_20'], 1, -1)

        # å¸ƒæ—å¸¦ä¿¡å·
        df['bb_signal'] = np.where(df['close'] < df['bb_lower_20_2'], 1,  # çªç ´ä¸‹è½¨ä¹°å…¥
                                  np.where(df['close'] > df['bb_upper_20_2'], -1, 0))  # çªç ´ä¸Šè½¨å–å‡º

        # MACDä¿¡å·
        df['macd_signal'] = np.where(df['macd_line_12_26'] > df['macd_signal_12_26_9'], 1, -1)

        # ç»¼åˆä¿¡å· (åŠ æƒå¹³å‡)
        weights = {'rsi': 0.25, 'ma': 0.25, 'bb': 0.25, 'macd': 0.25}
        df['composite_signal'] = (weights['rsi'] * df['rsi_signal'] +
                                 weights['ma'] * df['ma_signal'] +
                                 weights['bb'] * df['bb_signal'] +
                                 weights['macd'] * df['macd_signal'])

        # è®¡ç®—åŸºäºä¿¡å·çš„é¢„æµ‹æ”¶ç›Š
        df['predicted_returns'] = df['composite_signal'].shift(1) * df['returns']

        print(f"ğŸ“ˆ ç­–ç•¥æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(df.columns)} ä¸ªå› å­")
        return df

    return None

def analyze_factor_performance(data, factor_name='composite_signal'):
    """
    åˆ†æå› å­è¡¨ç°
    """
    if data is None or factor_name not in data.columns:
        print(f"âŒ å› å­ {factor_name} ä¸å­˜åœ¨æˆ–æ•°æ®ä¸ºç©º")
        return

    # è¿‡æ»¤æ‰NaNå€¼
    clean_data = data.dropna(subset=[factor_name, 'returns'])

    if clean_data.empty:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç”¨äºåˆ†æ {factor_name}")
        return

    # è®¡ç®—å› å­IC (Information Coefficient)
    ic = clean_data[[factor_name, 'returns']].corr().iloc[0, 1]
    print(f"ğŸ“Š {factor_name} å› å­IC: {ic:.4f}")

    # æŒ‰å› å­å€¼åˆ†ç»„
    clean_data = clean_data.dropna()
    if len(clean_data) > 10:
        clean_data['factor_decile'] = pd.qcut(clean_data[factor_name], min(10, len(clean_data)//10), labels=False, duplicates='drop')

        # è®¡ç®—å„åˆ†ä½çš„å¹³å‡æ”¶ç›Š
        factor_returns = clean_data.groupby('factor_decile')['returns'].mean()
        print(f"ğŸ“ˆ {factor_name} åˆ†ä½æ”¶ç›Šåˆ†æ:")
        print(factor_returns)

        # ä¿¡æ¯æ¯”ç‡
        ir = factor_returns.mean() / factor_returns.std() if factor_returns.std() != 0 else 0
        print(f"ğŸ“Š ä¿¡æ¯æ¯”ç‡ (IR): {ir:.4f}")

    return ic

def run_multi_factor_analysis():
    """
    è¿è¡Œå®Œæ•´çš„å¤šå› å­åˆ†æ
    """
    print("=" * 80)
    print("ğŸ¯ é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - å¤šå› å­ç­–ç•¥æ¼”ç¤º")
    print("=" * 80)

    # 1. æ˜¾ç¤ºå¯ç”¨å› å­
    available_factors = get_available_factors()

    # 2. è·å–æ•°æ®
    print("\nğŸ”„ è·å–è‚¡ç¥¨æ•°æ®...")
    fetcher = DataFetcher()

    try:
        # è·å–æ ·æœ¬è‚¡ç¥¨æ•°æ®
        data = fetcher.fetch('sh600023', '2025-01-01', '2026-01-01', source='ashare')

        if data is None or data.empty:
            print("âš ï¸  è·å–æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            dates = pd.date_range('2025-01-01', '2025-12-31', freq='D')
            n = len(dates)
            prices = 5 + np.cumsum(np.random.randn(n) * 0.02)  # éšæœºæ¸¸èµ°

            data = pd.DataFrame({
                'open': prices * (1 + np.random.randn(n) * 0.005),
                'high': prices * (1 + abs(np.random.randn(n)) * 0.01),
                'low': prices * (1 - abs(np.random.randn(n)) * 0.01),
                'close': prices,
                'volume': np.random.randint(1000000, 10000000, n)
            }, index=dates)

        # 3. æ„å»ºå¤šå› å­ç­–ç•¥
        print("\nğŸ—ï¸  æ„å»ºå¤šå› å­ç­–ç•¥...")
        enriched_data = build_multi_factor_strategy(data)

        if enriched_data is not None:
            print(f"âœ… ç­–ç•¥æ„å»ºå®Œæˆï¼Œå½“å‰åŒ…å« {len(enriched_data.columns)} ä¸ªå› å­")

            # 4. åˆ†æå› å­æ€§èƒ½
            print("\nğŸ“Š åˆ†æå› å­è¡¨ç°...")
            ic_score = analyze_factor_performance(enriched_data, 'composite_signal')

            # 5. è®¡ç®—ç­–ç•¥æ”¶ç›Š
            if 'predicted_returns' in enriched_data.columns:
                clean_returns = enriched_data[['predicted_returns', 'returns']].dropna()

                if not clean_returns.empty:
                    strategy_cumret = (1 + clean_returns['predicted_returns']).cumprod()
                    benchmark_cumret = (1 + clean_returns['returns']).cumprod()

                    print(f"\nğŸ“ˆ ç­–ç•¥ç´¯è®¡æ”¶ç›Š: {(strategy_cumret.iloc[-1] - 1) * 100:.2f}%")
                    print(f"ğŸ“ˆ ä¹°å…¥æŒæœ‰æ”¶ç›Š: {(benchmark_cumret.iloc[-1] - 1) * 100:.2f}%")

                    # è®¡ç®—å¹´åŒ–æ”¶ç›Šå’Œå¤æ™®æ¯”ç‡
                    total_return = strategy_cumret.iloc[-1] - 1
                    benchmark_return = benchmark_cumret.iloc[-1] - 1
                    n_years = len(clean_returns) / 252  # å‡è®¾252ä¸ªäº¤æ˜“æ—¥ä¸€å¹´

                    annual_return = (strategy_cumret.iloc[-1]) ** (1/n_years) - 1
                    benchmark_annual = (benchmark_cumret.iloc[-1]) ** (1/n_years) - 1

                    excess_return = annual_return - benchmark_annual
                    volatility = clean_returns['predicted_returns'].std() * np.sqrt(252)

                    sharpe_ratio = excess_return / volatility if volatility != 0 else 0

                    print(f"ğŸ“Š ç­–ç•¥å¹´åŒ–æ”¶ç›Š: {annual_return*100:.2f}%")
                    print(f"ğŸ“Š åŸºå‡†å¹´åŒ–æ”¶ç›Š: {benchmark_annual*100:.2f}%")
                    print(f"ğŸ“Š å¤æ™®æ¯”ç‡: {sharpe_ratio:.4f}")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def create_factor_exposure_matrix():
    """
    åˆ›å»ºå› å­æš´éœ²çŸ©é˜µç¤ºä¾‹
    """
    print("\nğŸ“‹ å› å­æš´éœ²çŸ©é˜µç¤ºä¾‹:")

    # æ¨¡æ‹Ÿå‡ ä¸ªå› å­çš„æš´éœ²åº¦
    factors = ['MA_Ratio', 'RSI_Signal', 'Volume_Momentum', 'Volatility_Regime', 'Momentum_Factor']
    stocks = ['SH600000', 'SH600023', 'SZ000001', 'SH600519', 'SZ300770']

    np.random.seed(42)
    exposure_matrix = pd.DataFrame(
        np.random.randn(len(stocks), len(factors)),
        index=stocks,
        columns=factors
    )

    print(exposure_matrix.round(3))

    # è®¡ç®—å› å­ç›¸å…³æ€§
    print("\nğŸ”— å› å­é—´ç›¸å…³æ€§:")
    factor_corr = exposure_matrix.corr()
    print(factor_corr.round(3))

    return exposure_matrix

if __name__ == "__main__":
    run_multi_factor_analysis()
    create_factor_exposure_matrix()

    print("\n" + "="*80)
    print("ğŸ’¡ å¤šå› å­ç­–ç•¥ä½¿ç”¨æŒ‡å—æ€»ç»“:")
    print("="*80)
    print("1. æ•°æ®è·å–: ä½¿ç”¨ DataFetcher è·å–å†å²æ•°æ®")
    print("2. å› å­å·¥ç¨‹: è®¡ç®—å¤šç§æŠ€æœ¯æŒ‡æ ‡ï¼ˆ100+å› å­ï¼‰")
    print("3. ç­–ç•¥æ„å»º: ç»“åˆå¤šä¸ªå› å­ç”Ÿæˆç»¼åˆä¿¡å·")
    print("4. é£é™©æ§åˆ¶: ç›‘æ§å› å­æš´éœ²å’Œç›¸å…³æ€§")
    print("5. ç»©æ•ˆè¯„ä¼°: è®¡ç®—æ”¶ç›Šã€ä¿¡æ¯æ¯”ç‡ã€å¤æ™®æ¯”ç‡ç­‰æŒ‡æ ‡")
    print("="*80)